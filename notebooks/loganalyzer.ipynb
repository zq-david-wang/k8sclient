{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hosts=\"10.19.137.140,10.19.137.141,10.19.137.142,10.19.137.143,10.19.137.144,10.19.137.145,10.19.137.146,\\\n",
    "10.19.137.151,10.19.137.152,10.19.137.153,10.19.137.154,10.19.137.156,10.19.137.157,10.19.137.158,\\\n",
    "10.19.137.159,10.19.140.12,10.19.140.15,10.19.140.4,10.19.140.7,10.19.140.9,10.19.137.147,10.19.137.148,\\\n",
    "10.19.137.149,10.19.137.150\".split(',')\n",
    "master = ['10.19.137.140', '10.19.137.141', '10.19.137.142']\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "line_pattern = re.compile(r\"(?P<type>[IWEF])\\s*(?P<time>\\d+ \\d+:\\d+:\\d+\\.\\d+)\\s*(?P<threadid>\\d+)\\s*(?P<filename>\\S+):(?P<linenum>\\d+)] (?P<message>.*)\")\n",
    "excludes=[\n",
    "    \"Log file created\",\n",
    "    \"Running on machine\",\n",
    "    \"Built with gc\",\n",
    "    \"Log line format\",\n",
    "]\n",
    "def collect_kubelet_logs():\n",
    "    r = []\n",
    "    for h in hosts:\n",
    "        fname = os.path.join(\".\", \"data\", \"kubelet\", h, \"kubelet.INFO\")\n",
    "        with open(fname) as f:\n",
    "            for l in f:\n",
    "                m = line_pattern.match(l)\n",
    "                if not m:\n",
    "                    ignore = False\n",
    "                    for e in excludes:\n",
    "                        if e in l:\n",
    "                            ignore = True\n",
    "                            break\n",
    "                    if not ignore:\n",
    "                        r.append({\n",
    "                            \"type\": 'U',\n",
    "                            \"time\": '0000 00:00:00.000000',\n",
    "                            \"threadid\": \"0\",\n",
    "                            \"filename\": \"NA\",\n",
    "                            \"linenum\": \"0\",\n",
    "                            \"message\": l.strip(),\n",
    "                            \"node\": h,\n",
    "                        })\n",
    "                else:\n",
    "                    v = m.groupdict()\n",
    "                    v.update({\"node\": h})\n",
    "                    r.append(v)\n",
    "    return pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = collect_kubelet_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>linenum</th>\n",
       "      <th>count</th>\n",
       "      <th>example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kubelet_volumes.go</td>\n",
       "      <td>128</td>\n",
       "      <td>1574352</td>\n",
       "      <td>Orphaned pod \"0626453a-30ce-11e8-80de-1866da19caf3\" found, but volume paths are still present on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pod_workers.go</td>\n",
       "      <td>186</td>\n",
       "      <td>950281</td>\n",
       "      <td>Error syncing pod a6c5b728-2c16-11e8-80de-1866da19caf3 (\"csi-xfshostpath-plugin-vfkd4_kube-syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reconciler.go</td>\n",
       "      <td>376</td>\n",
       "      <td>243479</td>\n",
       "      <td>Could not construct volume information: directory /data/kubelet/pods/0626453a-30ce-11e8-80de-186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nestedpendingoperations.go</td>\n",
       "      <td>263</td>\n",
       "      <td>93268</td>\n",
       "      <td>Operation for \"\\\"kubernetes.io/secret/a6c5b728-2c16-11e8-80de-1866da19caf3-sasecret\\\" (\\\"a6c5b72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kubelet.go</td>\n",
       "      <td>1645</td>\n",
       "      <td>78660</td>\n",
       "      <td>Unable to mount volumes for pod \"csi-xfshostpath-plugin-vfkd4_kube-system(a6c5b728-2c16-11e8-80d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>csi_mounter.go</td>\n",
       "      <td>345</td>\n",
       "      <td>58244</td>\n",
       "      <td>kubernetes.io/csi: failed to open volume data file [/data/kubelet/pods/09295bd6-2c18-11e8-80de-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>csi_plugin.go</td>\n",
       "      <td>164</td>\n",
       "      <td>58244</td>\n",
       "      <td>kubernetes.io/csi: plugin.ConstructVolumeSpec failed loading volume data using [/data/kubelet/po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kubelet_pods.go</td>\n",
       "      <td>855</td>\n",
       "      <td>55374</td>\n",
       "      <td>Unable to retrieve pull secret 4tools/ for 4tools/enn-haproxy-ssr-7c6bbc94f4-r5c9z due to resour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kuberuntime_manager.go</td>\n",
       "      <td>734</td>\n",
       "      <td>49707</td>\n",
       "      <td>container start failed: ErrImagePull: rpc error: code = Unknown desc = Error: image library/mypy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mount_linux.go</td>\n",
       "      <td>170</td>\n",
       "      <td>40445</td>\n",
       "      <td>could not determine device for path: \"/data/kubelet/pods/0626453a-30ce-11e8-80de-1866da19caf3/vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>secret.go</td>\n",
       "      <td>201</td>\n",
       "      <td>24346</td>\n",
       "      <td>Couldn't get secret kube-system/default-token-qdk0q: secrets \"default-token-qdk0q\" not found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>util.go</td>\n",
       "      <td>120</td>\n",
       "      <td>20998</td>\n",
       "      <td>Warning: \"/data/kubelet/pods/8e0f9c86-2200-11e8-b852-1866da19c727/volumes/kubernetes.io~cephfs/k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>conn.go</td>\n",
       "      <td>254</td>\n",
       "      <td>19486</td>\n",
       "      <td>Error on socket receive: read tcp 10.19.137.140:10250-&gt;10.19.137.142:57014: use of closed networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>container.go</td>\n",
       "      <td>393</td>\n",
       "      <td>19435</td>\n",
       "      <td>Failed to create summary reader for \"/kubepods/podc06ee507-04a3-11e8-9bc1-1866da19caf3/ab53c2486...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fs.go</td>\n",
       "      <td>418</td>\n",
       "      <td>19383</td>\n",
       "      <td>Stat fs failed. Error: no such file or directory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pod_container_deletor.go</td>\n",
       "      <td>77</td>\n",
       "      <td>15577</td>\n",
       "      <td>Container \"61399bc0c180ac75b674593383905b7d148dccb5096eae476cd09043c91ff923\" not found in pod's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>remote_runtime.go</td>\n",
       "      <td>209</td>\n",
       "      <td>11042</td>\n",
       "      <td>StartContainer \"4230124f0291ad23399a6761057d7c3175644ed9b7e3d724a2dd42a8fe387336\" from runtime s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mount_linux.go</td>\n",
       "      <td>139</td>\n",
       "      <td>10758</td>\n",
       "      <td>Mount failed: exit status 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>remote_image.go</td>\n",
       "      <td>108</td>\n",
       "      <td>7423</td>\n",
       "      <td>PullImage \"mypy:1.1\" from image service failed: rpc error: code = Unknown desc = Error: image li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kuberuntime_image.go</td>\n",
       "      <td>50</td>\n",
       "      <td>7423</td>\n",
       "      <td>Pull image \"mypy:1.1\" failed: rpc error: code = Unknown desc = Error: image library/mypy:1.1 not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>status_manager.go</td>\n",
       "      <td>474</td>\n",
       "      <td>5455</td>\n",
       "      <td>Failed to update status for pod \"client-10-19-137-141_k8sft(33677aec-31b0-11e8-87b5-1866da1a2629...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>conversion.go</td>\n",
       "      <td>110</td>\n",
       "      <td>2443</td>\n",
       "      <td>Could not get instant cpu stats: different number of cpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>status_manager.go</td>\n",
       "      <td>489</td>\n",
       "      <td>1241</td>\n",
       "      <td>Failed to delete status for pod \"lag-bkrfn_icy(7b5488e4-2c27-11e8-80de-1866da19caf3)\": pods \"lag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>reflector.go</td>\n",
       "      <td>341</td>\n",
       "      <td>1101</td>\n",
       "      <td>k8s.io/kubernetes/pkg/kubelet/kubelet.go:466: watch of *v1.Service ended with: too old resource ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>remote_runtime.go</td>\n",
       "      <td>332</td>\n",
       "      <td>1059</td>\n",
       "      <td>ExecSync 84560bb60b3867378365b96d59285d63c65c576ad4e3fc064f526a2c02196528 '/healthcheck.sh --rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>remote_runtime.go</td>\n",
       "      <td>278</td>\n",
       "      <td>864</td>\n",
       "      <td>ContainerStatus \"814bd85802d6d118a004388c6be84f3acd2d78b530fe8a1a83fb3dc79233ab3b\" from runtime ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kubelet_pods.go</td>\n",
       "      <td>1101</td>\n",
       "      <td>611</td>\n",
       "      <td>Failed killing the pod \"perf-test-deploy-6429-29-6-bcf497c7b-nmcmn\": failed to \"KillContainer\" f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>prober.go</td>\n",
       "      <td>103</td>\n",
       "      <td>558</td>\n",
       "      <td>No ref for container \"docker://f27556d5c0ec556e72054ff30efc135c3d24dd615d3ad554e02a710c058a5e11\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kuberuntime_container.go</td>\n",
       "      <td>66</td>\n",
       "      <td>513</td>\n",
       "      <td>Can't make a ref to pod \"client-10-19-137-141_k8sft(3f0155f5-31ae-11e8-87b5-1866da1a2629)\", cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>raw.go</td>\n",
       "      <td>87</td>\n",
       "      <td>430</td>\n",
       "      <td>Error while processing event (\"/sys/fs/cgroup/cpu,cpuacct/system.slice/run-r223c31a33040486286e7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>remote_runtime.go</td>\n",
       "      <td>92</td>\n",
       "      <td>14</td>\n",
       "      <td>RunPodSandbox from runtime service failed: rpc error: code = Unknown desc = failed to create a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>kuberuntime_sandbox.go</td>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "      <td>CreatePodSandbox for pod \"elasticsearch-fluent-nnqm7_monitor-system-log(d2d0cdc3-2e41-11e8-80de-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>kubelet.go</td>\n",
       "      <td>1352</td>\n",
       "      <td>14</td>\n",
       "      <td>Failed to start gpuManager stat /dev/nvidiactl: no such file or directory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>docker_sandbox.go</td>\n",
       "      <td>196</td>\n",
       "      <td>13</td>\n",
       "      <td>Both sandbox container and checkpoint for id \"c901fa22a9579f6cf516dead7c767025a92418951cfb9b5263...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>reflector.go</td>\n",
       "      <td>322</td>\n",
       "      <td>13</td>\n",
       "      <td>k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:47: Failed to watch *v1.Pod: Get https://127.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>remote_runtime.go</td>\n",
       "      <td>246</td>\n",
       "      <td>12</td>\n",
       "      <td>RemoveContainer \"0671f76a6bd1d727ebe25ab15a42a5178604cea804124f7499e89e471b17cc1c\" from runtime ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>kubelet_node_status.go</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>Unable to register node \"10.19.137.147\" with API server: Post https://127.0.0.1:6442/api/v1/node...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>exec.go</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>error executing command in container: tls: use of closed connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>event.go</td>\n",
       "      <td>209</td>\n",
       "      <td>8</td>\n",
       "      <td>Unable to write event: 'Patch https://127.0.0.1:6442/api/v1/namespaces/api4ns0323232441/events/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>kubelet_node_status.go</td>\n",
       "      <td>378</td>\n",
       "      <td>7</td>\n",
       "      <td>Unable to update node status: update node status exceeds retry count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>xfsquotamanager.go</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>NewXFSQuotaManager init error :xfs_quota mount path /xfs is not exist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>kubelet_node_status.go</td>\n",
       "      <td>382</td>\n",
       "      <td>6</td>\n",
       "      <td>Unable to update node disk quota info: error getting node \"10.19.137.143\": Get https://127.0.0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>eviction_manager.go</td>\n",
       "      <td>238</td>\n",
       "      <td>5</td>\n",
       "      <td>eviction manager: unexpected err: failed to get imageFs stats: failed to get image stats: rpc er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>factory.go</td>\n",
       "      <td>343</td>\n",
       "      <td>4</td>\n",
       "      <td>devicemapper filesystem stats will not be reported: usage of thin_ls is disabled to preserve iops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>kubelet_node_status.go</td>\n",
       "      <td>981</td>\n",
       "      <td>3</td>\n",
       "      <td>Failed to set some node status fields: failed to validate nodeIP: route ip+net: no such network ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>status_manager.go</td>\n",
       "      <td>459</td>\n",
       "      <td>3</td>\n",
       "      <td>Failed to get status for pod \"api4dep0326135233-7b8cd7b9c-9hrph_api4ns0323232441(9aac4782-30c1-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>remote_image.go</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>ListImages with filter nil from image service failed: rpc error: code = Unknown desc = Error res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>container_manager_linux.go</td>\n",
       "      <td>801</td>\n",
       "      <td>2</td>\n",
       "      <td>MemoryAccounting not enabled for pid: 13150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>container_manager_linux.go</td>\n",
       "      <td>798</td>\n",
       "      <td>2</td>\n",
       "      <td>CPUAccounting not enabled for pid: 13150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>generic.go</td>\n",
       "      <td>271</td>\n",
       "      <td>2</td>\n",
       "      <td>PLEG: pod nfsftp-68d59b8ffd-6c7mz/cc-itg failed reinspection: rpc error: code = Unknown desc = E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>docker_container.go</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>Deleted previously existing symlink file: \"/var/log/pods/1f88ca78-28dd-11e8-80de-1866da19caf3/pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>xfsquotamanager.go</td>\n",
       "      <td>436</td>\n",
       "      <td>1</td>\n",
       "      <td>NewXFSQuotaManager init error :xfs_quota mount path /xfs is not exist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>kuberuntime_image.go</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>ListImages failed: rpc error: code = Unknown desc = Error response from daemon: layer does not e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>eviction_manager.go</td>\n",
       "      <td>332</td>\n",
       "      <td>1</td>\n",
       "      <td>eviction manager: attempting to reclaim imagefs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>eviction_manager.go</td>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "      <td>eviction manager: unexpected error when attempting to reduce imagefs pressure: wanted to free 92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>reconciler.go</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>operationExecutor.MountVolume failed (controllerAttachDetachEnabled true) for volume \"kube-confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>image_gc_manager.go</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>[imageGCManager] Failed to monitor images: rpc error: code = Unknown desc = Error response from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>pv_node_affinity_manager.go</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>doClearOrphanQuotaPath err:Get https://127.0.0.1:6442/api/v1/persistentvolumes: dial tcp 127.0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>kuberuntime_image.go</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>ListImages failed: rpc error: code = Unknown desc = Error response from daemon: layer does not e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>xfsquotamanager.go</td>\n",
       "      <td>438</td>\n",
       "      <td>1</td>\n",
       "      <td>NewXFSQuotaManager init error :initQuotaXFSDisk error =initQuotaXFSDisk no xfs disk project quot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename linenum    count  \\\n",
       "0            kubelet_volumes.go     128  1574352   \n",
       "1                pod_workers.go     186   950281   \n",
       "2                 reconciler.go     376   243479   \n",
       "3    nestedpendingoperations.go     263    93268   \n",
       "4                    kubelet.go    1645    78660   \n",
       "5                csi_mounter.go     345    58244   \n",
       "6                 csi_plugin.go     164    58244   \n",
       "7               kubelet_pods.go     855    55374   \n",
       "8        kuberuntime_manager.go     734    49707   \n",
       "9                mount_linux.go     170    40445   \n",
       "10                    secret.go     201    24346   \n",
       "11                      util.go     120    20998   \n",
       "12                      conn.go     254    19486   \n",
       "13                 container.go     393    19435   \n",
       "14                        fs.go     418    19383   \n",
       "15     pod_container_deletor.go      77    15577   \n",
       "16            remote_runtime.go     209    11042   \n",
       "17               mount_linux.go     139    10758   \n",
       "18              remote_image.go     108     7423   \n",
       "19         kuberuntime_image.go      50     7423   \n",
       "20            status_manager.go     474     5455   \n",
       "21                conversion.go     110     2443   \n",
       "22            status_manager.go     489     1241   \n",
       "23                 reflector.go     341     1101   \n",
       "24            remote_runtime.go     332     1059   \n",
       "25            remote_runtime.go     278      864   \n",
       "26              kubelet_pods.go    1101      611   \n",
       "27                    prober.go     103      558   \n",
       "28     kuberuntime_container.go      66      513   \n",
       "29                       raw.go      87      430   \n",
       "..                          ...     ...      ...   \n",
       "68            remote_runtime.go      92       14   \n",
       "69       kuberuntime_sandbox.go      54       14   \n",
       "70                   kubelet.go    1352       14   \n",
       "71            docker_sandbox.go     196       13   \n",
       "72                 reflector.go     322       13   \n",
       "73            remote_runtime.go     246       12   \n",
       "74       kubelet_node_status.go     109        9   \n",
       "75                      exec.go      71        9   \n",
       "76                     event.go     209        8   \n",
       "77       kubelet_node_status.go     378        7   \n",
       "78           xfsquotamanager.go     433        7   \n",
       "79       kubelet_node_status.go     382        6   \n",
       "80          eviction_manager.go     238        5   \n",
       "81                   factory.go     343        4   \n",
       "82       kubelet_node_status.go     981        3   \n",
       "83            status_manager.go     459        3   \n",
       "84              remote_image.go      67        2   \n",
       "85   container_manager_linux.go     801        2   \n",
       "86   container_manager_linux.go     798        2   \n",
       "87                   generic.go     271        2   \n",
       "88          docker_container.go     193        1   \n",
       "89           xfsquotamanager.go     436        1   \n",
       "90         kuberuntime_image.go     140        1   \n",
       "91          eviction_manager.go     332        1   \n",
       "92          eviction_manager.go     435        1   \n",
       "93                reconciler.go     258        1   \n",
       "94          image_gc_manager.go     173        1   \n",
       "95  pv_node_affinity_manager.go     201        1   \n",
       "96         kuberuntime_image.go     106        1   \n",
       "97           xfsquotamanager.go     438        1   \n",
       "\n",
       "                                                                                                example  \n",
       "0   Orphaned pod \"0626453a-30ce-11e8-80de-1866da19caf3\" found, but volume paths are still present on...  \n",
       "1   Error syncing pod a6c5b728-2c16-11e8-80de-1866da19caf3 (\"csi-xfshostpath-plugin-vfkd4_kube-syste...  \n",
       "2   Could not construct volume information: directory /data/kubelet/pods/0626453a-30ce-11e8-80de-186...  \n",
       "3   Operation for \"\\\"kubernetes.io/secret/a6c5b728-2c16-11e8-80de-1866da19caf3-sasecret\\\" (\\\"a6c5b72...  \n",
       "4   Unable to mount volumes for pod \"csi-xfshostpath-plugin-vfkd4_kube-system(a6c5b728-2c16-11e8-80d...  \n",
       "5   kubernetes.io/csi: failed to open volume data file [/data/kubelet/pods/09295bd6-2c18-11e8-80de-1...  \n",
       "6   kubernetes.io/csi: plugin.ConstructVolumeSpec failed loading volume data using [/data/kubelet/po...  \n",
       "7   Unable to retrieve pull secret 4tools/ for 4tools/enn-haproxy-ssr-7c6bbc94f4-r5c9z due to resour...  \n",
       "8   container start failed: ErrImagePull: rpc error: code = Unknown desc = Error: image library/mypy...  \n",
       "9   could not determine device for path: \"/data/kubelet/pods/0626453a-30ce-11e8-80de-1866da19caf3/vo...  \n",
       "10         Couldn't get secret kube-system/default-token-qdk0q: secrets \"default-token-qdk0q\" not found  \n",
       "11  Warning: \"/data/kubelet/pods/8e0f9c86-2200-11e8-b852-1866da19c727/volumes/kubernetes.io~cephfs/k...  \n",
       "12  Error on socket receive: read tcp 10.19.137.140:10250->10.19.137.142:57014: use of closed networ...  \n",
       "13  Failed to create summary reader for \"/kubepods/podc06ee507-04a3-11e8-9bc1-1866da19caf3/ab53c2486...  \n",
       "14                                                     Stat fs failed. Error: no such file or directory  \n",
       "15  Container \"61399bc0c180ac75b674593383905b7d148dccb5096eae476cd09043c91ff923\" not found in pod's ...  \n",
       "16  StartContainer \"4230124f0291ad23399a6761057d7c3175644ed9b7e3d724a2dd42a8fe387336\" from runtime s...  \n",
       "17                                                                         Mount failed: exit status 32  \n",
       "18  PullImage \"mypy:1.1\" from image service failed: rpc error: code = Unknown desc = Error: image li...  \n",
       "19  Pull image \"mypy:1.1\" failed: rpc error: code = Unknown desc = Error: image library/mypy:1.1 not...  \n",
       "20  Failed to update status for pod \"client-10-19-137-141_k8sft(33677aec-31b0-11e8-87b5-1866da1a2629...  \n",
       "21                                            Could not get instant cpu stats: different number of cpus  \n",
       "22  Failed to delete status for pod \"lag-bkrfn_icy(7b5488e4-2c27-11e8-80de-1866da19caf3)\": pods \"lag...  \n",
       "23  k8s.io/kubernetes/pkg/kubelet/kubelet.go:466: watch of *v1.Service ended with: too old resource ...  \n",
       "24  ExecSync 84560bb60b3867378365b96d59285d63c65c576ad4e3fc064f526a2c02196528 '/healthcheck.sh --rea...  \n",
       "25  ContainerStatus \"814bd85802d6d118a004388c6be84f3acd2d78b530fe8a1a83fb3dc79233ab3b\" from runtime ...  \n",
       "26  Failed killing the pod \"perf-test-deploy-6429-29-6-bcf497c7b-nmcmn\": failed to \"KillContainer\" f...  \n",
       "27  No ref for container \"docker://f27556d5c0ec556e72054ff30efc135c3d24dd615d3ad554e02a710c058a5e11\"...  \n",
       "28  Can't make a ref to pod \"client-10-19-137-141_k8sft(3f0155f5-31ae-11e8-87b5-1866da1a2629)\", cont...  \n",
       "29  Error while processing event (\"/sys/fs/cgroup/cpu,cpuacct/system.slice/run-r223c31a33040486286e7...  \n",
       "..                                                                                                  ...  \n",
       "68  RunPodSandbox from runtime service failed: rpc error: code = Unknown desc = failed to create a s...  \n",
       "69  CreatePodSandbox for pod \"elasticsearch-fluent-nnqm7_monitor-system-log(d2d0cdc3-2e41-11e8-80de-...  \n",
       "70                            Failed to start gpuManager stat /dev/nvidiactl: no such file or directory  \n",
       "71  Both sandbox container and checkpoint for id \"c901fa22a9579f6cf516dead7c767025a92418951cfb9b5263...  \n",
       "72  k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:47: Failed to watch *v1.Pod: Get https://127.0...  \n",
       "73  RemoveContainer \"0671f76a6bd1d727ebe25ab15a42a5178604cea804124f7499e89e471b17cc1c\" from runtime ...  \n",
       "74  Unable to register node \"10.19.137.147\" with API server: Post https://127.0.0.1:6442/api/v1/node...  \n",
       "75                                  error executing command in container: tls: use of closed connection  \n",
       "76  Unable to write event: 'Patch https://127.0.0.1:6442/api/v1/namespaces/api4ns0323232441/events/a...  \n",
       "77                                 Unable to update node status: update node status exceeds retry count  \n",
       "78                                NewXFSQuotaManager init error :xfs_quota mount path /xfs is not exist  \n",
       "79  Unable to update node disk quota info: error getting node \"10.19.137.143\": Get https://127.0.0.1...  \n",
       "80  eviction manager: unexpected err: failed to get imageFs stats: failed to get image stats: rpc er...  \n",
       "81    devicemapper filesystem stats will not be reported: usage of thin_ls is disabled to preserve iops  \n",
       "82  Failed to set some node status fields: failed to validate nodeIP: route ip+net: no such network ...  \n",
       "83  Failed to get status for pod \"api4dep0326135233-7b8cd7b9c-9hrph_api4ns0323232441(9aac4782-30c1-1...  \n",
       "84  ListImages with filter nil from image service failed: rpc error: code = Unknown desc = Error res...  \n",
       "85                                                          MemoryAccounting not enabled for pid: 13150  \n",
       "86                                                             CPUAccounting not enabled for pid: 13150  \n",
       "87  PLEG: pod nfsftp-68d59b8ffd-6c7mz/cc-itg failed reinspection: rpc error: code = Unknown desc = E...  \n",
       "88  Deleted previously existing symlink file: \"/var/log/pods/1f88ca78-28dd-11e8-80de-1866da19caf3/pr...  \n",
       "89                                NewXFSQuotaManager init error :xfs_quota mount path /xfs is not exist  \n",
       "90  ListImages failed: rpc error: code = Unknown desc = Error response from daemon: layer does not e...  \n",
       "91                                                      eviction manager: attempting to reclaim imagefs  \n",
       "92  eviction manager: unexpected error when attempting to reduce imagefs pressure: wanted to free 92...  \n",
       "93  operationExecutor.MountVolume failed (controllerAttachDetachEnabled true) for volume \"kube-confi...  \n",
       "94  [imageGCManager] Failed to monitor images: rpc error: code = Unknown desc = Error response from ...  \n",
       "95  doClearOrphanQuotaPath err:Get https://127.0.0.1:6442/api/v1/persistentvolumes: dial tcp 127.0.0...  \n",
       "96  ListImages failed: rpc error: code = Unknown desc = Error response from daemon: layer does not e...  \n",
       "97  NewXFSQuotaManager init error :initQuotaXFSDisk error =initQuotaXFSDisk no xfs disk project quot...  \n",
       "\n",
       "[98 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pd.options.display.max_colwidth=100\n",
    "def count(x):\n",
    "    return x.shape[0]\n",
    "def example(x):\n",
    "    return x.iloc[0]\n",
    "\n",
    "df[(df.type != 'I') & (df.type != 'U')].groupby(['filename', 'linenum'])['message'].agg([count, example]).sort_values(by=\"count\", ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5211347                                                                          Mounting command: systemd-run\n",
       "5211348    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5211349                             Output: Running scope as unit: run-r8ba406cb803e41cc93044fc700a051a0.scope\n",
       "5211350    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5211351                                                                                                       \n",
       "5211358                                                                          Mounting command: systemd-run\n",
       "5211359    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5211360                             Output: Running scope as unit: run-r6a3e884fb88d4f6fa946c0a9d51a0d31.scope\n",
       "5211361    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5211362                                                                                                       \n",
       "5211382                                                                          Mounting command: systemd-run\n",
       "5211383    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5211384                             Output: Running scope as unit: run-r199531a5dbfc4e51a98b9a50ff1fa8fd.scope\n",
       "5211385    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5211386                                                                                                       \n",
       "5211405                                                                          Mounting command: systemd-run\n",
       "5211406    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5211407                             Output: Running scope as unit: run-rb56f46db86df41f1b121eba1eec7cbfb.scope\n",
       "5211408    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5211409                                                                                                       \n",
       "5211423                                                                          Mounting command: systemd-run\n",
       "5211424    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5211425                             Output: Running scope as unit: run-radea3f5d7ed04ff9aa2ebff8e2a22b1b.scope\n",
       "5211426    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5211427                                                                                                       \n",
       "5211480                                                                          Mounting command: systemd-run\n",
       "5211481    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5211482                             Output: Running scope as unit: run-rff05e6ad798e4bc4a34e2ef95d6b6f7d.scope\n",
       "5211483    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5211484                                                                                                       \n",
       "                                                          ...                                                 \n",
       "5764405                                                                          Mounting command: systemd-run\n",
       "5764406    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5764407                             Output: Running scope as unit: run-r0199adb8b513480fa3104206a4a48f42.scope\n",
       "5764408    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5764409                                                                                                       \n",
       "5764488                                                                          Mounting command: systemd-run\n",
       "5764489    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5764490                             Output: Running scope as unit: run-ra2e40eb385eb44b5be1c9702eae8c705.scope\n",
       "5764491    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5764492                                                                                                       \n",
       "5764562                                                                          Mounting command: systemd-run\n",
       "5764563    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5764564                             Output: Running scope as unit: run-r86e87300e94a4f9699ecaffcf7535ee9.scope\n",
       "5764565    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5764566                                                                                                       \n",
       "5764642                                                                          Mounting command: systemd-run\n",
       "5764643    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5764644                             Output: Running scope as unit: run-r44403bffda5842a2b1f99b0eb44def6a.scope\n",
       "5764645    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5764646                                                                                                       \n",
       "5764719                                                                          Mounting command: systemd-run\n",
       "5764720    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5764721                             Output: Running scope as unit: run-rba0e6c03bc514f7f8ca41d79e255dd74.scope\n",
       "5764722    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5764723                                                                                                       \n",
       "5764798                                                                          Mounting command: systemd-run\n",
       "5764799    Mounting arguments: --description=Kubernetes transient mount for /data/kubelet/pods/8e0f9c86-220...\n",
       "5764800                             Output: Running scope as unit: run-r0a01f3eff0b841a1943fdb33c5145188.scope\n",
       "5764801    mount: special device 10.19.137.144:6789,10.19.137.145:6789,10.19.137.146:6789:/monitor-system-a...\n",
       "5764802                                                                                                       \n",
       "Name: message, Length: 53152, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[(df.type == 'U')].groupby(\"node\").count().reset_index()\n",
    "df[(df.type == 'U') & (df.node == '10.19.140.7')]['message']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
